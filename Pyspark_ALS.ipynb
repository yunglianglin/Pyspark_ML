{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawUData=sc.textFile(\"hdfs://mycluster/user/oracle/data/u.data\")\n",
    "rawUData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['196', '242', '3'],\n",
       " ['186', '302', '3'],\n",
       " ['22', '377', '1'],\n",
       " ['244', '51', '2'],\n",
       " ['166', '346', '1']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawRating = rawUData.map(lambda x : x.split(\"\\t\")[:3])\n",
    "rawRating.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(196, 242, 3), (186, 302, 3), (22, 377, 1), (244, 51, 2), (166, 346, 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(user_id, item_id, rating)\n",
    "ratingsRDD = rawRating.map(lambda x : (int(x[0]),int(x[1]),int(x[2])))\n",
    "ratingsRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator #evaluate ALS model\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder, TrainValidationSplitModel\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('als_model').getOrCreate()\n",
    "\n",
    "#create training set and test set\n",
    "#covert RDD to DataFrame cuz .fit() only accept dataframe\n",
    "ratingsRDD = spark.createDataFrame(ratingsRDD, [\"userId\", \"movieId\", \"rating\"])\n",
    "(training, test)=ratingsRDD.randomSplit([0.8, 0.2], 35)\n",
    "\n",
    "#create ALS model\n",
    "#coldStart-> avoid empty prediction value\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\", nonnegative = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune model using ParamGridBuilder\n",
    "param_grid = ParamGridBuilder()\\\n",
    "             .addGrid(als.rank, [12, 13, 14])\\\n",
    "             .addGrid(als.maxIter, [18, 19, 20])\\\n",
    "             .addGrid(als.regParam, [.17, .18, .19])\\\n",
    "             .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define evaluator as RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build cross validation using TrainValidationSplit\n",
    "tvs = TrainValidationSplit(\n",
    "        estimator=als,\n",
    "        estimatorParamMaps=param_grid,\n",
    "        evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit ALS model to training data\n",
    "model = tvs.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract best model from the tuning exercise using ParanGridBuilder\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.tuning.TrainValidationSplitModel"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model-> TrainValidationSplitModel is a collection of ALSModels with dirfferent set of hyperparameter\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALSModel"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_model-> Extract the best model from the collection\n",
    "type(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate predictions and evaluate using RMSE\n",
    "predictions = best_model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=0.9274000847657947\n",
      "**Best Model**\n",
      "  Rank:\n",
      "  MaxIter:\n",
      "  RegParam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"RMSE=\" +str(rmse))\n",
    "print(\"**Best Model**\")\n",
    "print(\"  Rank:\"),best_model.rank\n",
    "print(\"  MaxIter:\"), best_model._java_obj.parent().getMaxIter()\n",
    "print(\"  RegParam\"), best_model._java_obj.parent().getRegParam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load ALSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the best model to HDFS\n",
    "best_model.save(\"hdfs://mycluster/user/oracle/data/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model from HDFS and reuse it\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.tuning import TrainValidationSplit, TrainValidationSplitModel\n",
    "re_model = ALSModel.load(\"hdfs://mycluster/user/oracle/data/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS_42eba90bc6fef07ad82d"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend movies by UserId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_recs_for_user(recs):\n",
    "    recs = recs.select(\"recommendations.movieId\", \"recommendations.rating\")\n",
    "    movies = recs.select(\"movieId\").toPandas().iloc[0,0]\n",
    "    ratings = recs.select(\"rating\").toPandas().iloc[0,0]\n",
    "    ratings_matrix = pd.DataFrame(movies, columns = [\"movieId\"])\n",
    "    ratings_matrix[\"ratings\"] = ratings\n",
    "    ratings_matrix_ps = sqlContext.createDataFrame(ratings_matrix)\n",
    "    return ratings_matrix_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId : 481\n",
      "+-------+------------------+\n",
      "|movieId|           ratings|\n",
      "+-------+------------------+\n",
      "|   1450| 4.800578594207764|\n",
      "|   1449| 4.732533931732178|\n",
      "|   1398| 4.686621189117432|\n",
      "|   1642| 4.589539051055908|\n",
      "|   1122|4.5377373695373535|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = input(\"userId : \")\n",
    "topKRecs = re_model.recommendForAllUsers(5) \n",
    "get_recs_for_user(topKRecs.where(topKRecs.userId == text)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend users for movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recs_for_item(recs):\n",
    "    recs = recs.select(\"recommendations.userId\", \"recommendations.rating\")\n",
    "    users = recs.select(\"userId\").toPandas().iloc[0,0]\n",
    "    ratings = recs.select(\"rating\").toPandas().iloc[0,0]\n",
    "    ratings_matrix = pd.DataFrame(users, columns = [\"userId\"])\n",
    "    ratings_matrix[\"ratings\"] = ratings\n",
    "    ratings_matrix_ps = sqlContext.createDataFrame(ratings_matrix)\n",
    "    return ratings_matrix_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input(\"movieId : \")\n",
    "item = best_model.recommendForAllItems(5)\n",
    "get_recs_for_item(item.where(item.movieId == x)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend movies to all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = best_model.recommendForAllUsers(5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_p = result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = result_p['userId'].tolist()\n",
    "for user in y[0:5]:\n",
    "    print(\"userId : \" + str(user))\n",
    "    get_recs_for_user(topKRecs.where(topKRecs.userId == user)).show()\n",
    "    print(\"=========================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
